Implementing Retrieval-Augmented Genera-
tion (RAG) systems is inherently complex,
requiring deep understanding of data, use
cases, and intricate design decisions. Addi-
tionally, evaluating these systems presents sig-
nificant challenges, necessitating assessment of
both retrieval accuracy and generative quality
through a multi-faceted approach. We intro-
duce RAG F OUNDRY , an open-source frame-
work for augmenting large language models
for RAG use cases. RAG F OUNDRY inte-
grates data creation, training, inference and
evaluation into a single workflow, facilitating
the creation of data-augmented datasets for
training and evaluating large language mod-
els in RAG settings. This integration en-
ables rapid prototyping and experimentation
with various RAG techniques, allowing users
to easily generate datasets and train RAG
models using internal or specialized knowl-
edge sources. We demonstrate the frame-
work effectiveness by augmenting and fine-
tuning Llama-3 and Phi-3 models with diverse
RAG configurations, showcasing consistent im-
provements across three knowledge-intensive
datasets. Code is released as open-source in
https://github.com/IntelLabs/RAGFoundry .